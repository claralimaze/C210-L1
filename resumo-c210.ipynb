{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.cluster import KMeans\nimport random\nfrom queue import PriorityQueue\n\n# 1. Criando um DataFrame simples com pandas (Machine Learning e Pandas)\ndata = {'feature1': [1, 2, 3, 4, 5], 'feature2': [5, 4, 3, 2, 1], 'target': [1, 0, 1, 0, 1]}\ndf = pd.DataFrame(data)\n\n# 2. Aplicando Regressão Linear (LR)\nX = df[['feature1', 'feature2']]\ny = df['target']\nregressor = LinearRegression()\nregressor.fit(X, y)\npredictions = regressor.predict(X)\nprint(f'Regressão Linear - Predições: {predictions}')\n\n# 3. Classificação com KNN\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X, y)\nknn_predictions = knn.predict(X)\nprint(f'KNN - Predições: {knn_predictions}')\n\n# 4. Clusterização com KMeans\nkmeans = KMeans(n_clusters=2)\nkmeans.fit(X)\nlabels = kmeans.predict(X)\nprint(f'KMeans - Labels: {labels}')\n\n# 5. Busca Cega (DFS)\ndef busca_profundidade(grafo, inicio, objetivo, visitados=None):\n    if visitados is None:\n        visitados = set()\n    visitados.add(inicio)\n    if inicio == objetivo:\n        return True\n    for vizinho in grafo[inicio]:\n        if vizinho not in visitados:\n            if busca_profundidade(grafo, vizinho, objetivo, visitados):\n                return True\n    return False\n\n# Exemplo de grafo para busca cega\ngrafo = {'A': ['B', 'C'], 'B': ['D'], 'C': ['D'], 'D': []}\nprint(f'Busca Cega - Encontrou o objetivo? {busca_profundidade(grafo, \"A\", \"D\")}')\n\n# 6. Busca Informada (A*)\ndef a_star(grafo, inicio, objetivo):\n    pq = PriorityQueue()\n    pq.put((0, inicio))\n    came_from = {}\n    g_score = {inicio: 0}\n    \n    while not pq.empty():\n        _, current = pq.get()\n        if current == objetivo:\n            return reconstruct_path(came_from, current)\n        \n        for vizinho, custo in grafo[current]:\n            temp_g_score = g_score[current] + custo\n            if vizinho not in g_score or temp_g_score < g_score[vizinho]:\n                g_score[vizinho] = temp_g_score\n                pq.put((g_score[vizinho], vizinho))\n                came_from[vizinho] = current\n    return None\n\n# Função para reconstruir o caminho\ndef reconstruct_path(came_from, current):\n    path = [current]\n    while current in came_from:\n        current = came_from[current]\n        path.append(current)\n    return path[::-1]\n\n# Exemplo de grafo para A*\ngrafo_a_star = {'A': [('B', 1), ('C', 4)], 'B': [('D', 2)], 'C': [('D', 5)], 'D': []}\nprint(f'Busca Informada (A*) - Caminho: {a_star(grafo_a_star, \"A\", \"D\")}')\n\n# 7. Algoritmo Genético\ndef crossover(pai1, pai2):\n    ponto = random.randint(1, len(pai1) - 1)\n    filho1 = pai1[:ponto] + pai2[ponto:]\n    filho2 = pai2[:ponto] + pai1[ponto:]\n    return filho1, filho2\n\n# Exemplo de crossover\npai1 = [1, 0, 1, 1]\npai2 = [0, 1, 0, 1]\nfilho1, filho2 = crossover(pai1, pai2)\nprint(f'Algoritmo Genético - Filhos: {filho1}, {filho2}')\n\n# 8. PSO (Particle Swarm Optimization)\nclass Particula:\n    def __init__(self, posicao, velocidade):\n        self.posicao = posicao\n        self.velocidade = velocidade\n        self.best_pos = posicao\n        self.best_score = float('inf')\n\n    def atualizar(self, global_best_pos):\n        w = 0.5  # fator de inércia\n        c1 = 1.5  # fator de aprendizado\n        c2 = 1.5  # fator de aprendizado\n\n        # Atualizar velocidade e posição\n        for i in range(len(self.posicao)):\n            r1, r2 = random.random(), random.random()\n            self.velocidade[i] = w * self.velocidade[i] + c1 * r1 * (self.best_pos[i] - self.posicao[i]) + c2 * r2 * (global_best_pos[i] - self.posicao[i])\n            self.posicao[i] += self.velocidade[i]\n\n# Inicializando partículas e otimizando\nparticulas = [Particula([random.random(), random.random()], [0, 0]) for _ in range(5)]\nglobal_best_pos = [0, 0]\nfor part in particulas:\n    part.atualizar(global_best_pos)\n    print(f'PSO - Posição final da partícula: {part.posicao}')\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-24T11:47:46.353456Z","iopub.execute_input":"2025-04-24T11:47:46.353777Z","iopub.status.idle":"2025-04-24T11:47:49.012578Z","shell.execute_reply.started":"2025-04-24T11:47:46.353745Z","shell.execute_reply":"2025-04-24T11:47:49.010858Z"}},"outputs":[{"name":"stdout","text":"Regressão Linear - Predições: [0.6 0.6 0.6 0.6 0.6]\nKNN - Predições: [1 1 0 1 1]\nKMeans - Labels: [0 0 1 1 1]\nBusca Cega - Encontrou o objetivo? True\nBusca Informada (A*) - Caminho: ['A', 'B', 'D']\nAlgoritmo Genético - Filhos: [1, 0, 1, 1], [0, 1, 0, 1]\nPSO - Posição final da partícula: [-0.015263408732909656, 0.5506200177700598]\nPSO - Posição final da partícula: [-0.1860965108151179, 0.03135001406062132]\nPSO - Posição final da partícula: [0.26657135916586655, -0.09357440490393854]\nPSO - Posição final da partícula: [-0.11413753383642422, -0.02531016601999536]\nPSO - Posição final da partícula: [0.011539612795992138, 0.37986025179326693]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":1}]}